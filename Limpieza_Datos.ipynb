{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "835fe7ac-9489-4987-a172-cbc4e2f8a24f",
   "metadata": {},
   "source": [
    "![Banner_Visualización&Storytelling.png](Banner_Visualización&Storytelling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ee25b6-ffe2-45c6-b3a2-604e7a0e31d4",
   "metadata": {},
   "source": [
    "## Dashboard 2: visualización y documentación para narrar a un equipo de trabajo\n",
    "### Modelar los datos \n",
    "\n",
    "En el notebook, se realizarán los siguientes pasos de modelado: \n",
    "\n",
    "1. Extraer la base de datos “Ask A Manager Salary Survey 2021” de AskAManager.org (https://docs.google.com/spreadsheets/d/1IPS5dBSGtwYVbjsfbaMCYIWnOuRmJcbequohNxCyGVw/edit?resourcekey#gid=1625408792)  \n",
    "\n",
    "2. Limpiar los campos de “Country” y “City” para homogenizar los nombres de los lugares. \n",
    "\n",
    "3. Crear 2 campos nuevos: “salario_anual” y “compensaciones” convirtiendo sueldos y compensaciones a Pesos Colombianos basados en la tasa de cambio del día que hacen el ejercicio. \n",
    "\n",
    "4. Crear un campo adicional sumando salario anual y compensaciones en pesos colombianos.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7928bc1-cd74-4419-8db6-c18e42850681",
   "metadata": {},
   "source": [
    "### Librerías a importar\n",
    "\n",
    "A continuación, se muestran las librerias a importar para poder implementar los procedimientos de este notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eea6cce3-b43b-4d7b-bb48-42ce682d884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dataprep.clean import clean_country\n",
    "import warnings\n",
    "from fuzzywuzzy import process, fuzz\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6189b7-6b54-484c-9a68-2cea5cfa0e43",
   "metadata": {},
   "source": [
    "### 1. Importar la base de datos\n",
    "\n",
    "Se emplea la libreria de pandas para importar el archivo de datos a la sesión de trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58e8c2b1-c654-409e-a883-56bf065ffe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.csv\", thousands=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70b9cc4b-5577-4d5c-a530-0270806fbd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de observaciones en la base de datos: 27936\n",
      "Número de columnas en la base de datos: 18\n"
     ]
    }
   ],
   "source": [
    "#Tamaño del dataset\n",
    "print(f\"Número de observaciones en la base de datos: {df.shape[0]}\")\n",
    "print(f\"Número de columnas en la base de datos: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfe3868-4afb-4b90-b04a-12221f0628e3",
   "metadata": {},
   "source": [
    "#### Renombrar las columnas del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5035c312-ade9-47a0-ab65-e6df3a3003e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timestamp', 'age_range', 'industry', 'job_title',\n",
      "       'additional_context_job', 'annual_salary',\n",
      "       'additional_monetary_compensation', 'currency', 'other_currency',\n",
      "       'additional_context_income', 'country', 'state_US', 'city',\n",
      "       'years_work_experience', 'years_work_experience_field',\n",
      "       'level_education', 'gender', 'race'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Old column names\n",
    "old_col_names = df.columns.values\n",
    "\n",
    "# New column names\n",
    "new_col_names = ['timestamp', 'age_range','industry','job_title','additional_context_job','annual_salary','additional_monetary_compensation','currency','other_currency','additional_context_income','country','state_US','city','years_work_experience','years_work_experience_field','level_education','gender','race']\n",
    "\n",
    "# Create a dictionary mapping old column names to new column names\n",
    "col_name_map = {old: new for old, new in zip(old_col_names, new_col_names)}\n",
    "\n",
    "# Use the rename method to update the column names\n",
    "df.rename(columns=col_name_map, inplace=True)\n",
    "\n",
    "# Verify that the columns have been renamed\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6c6797-2959-42a9-a4b7-6b46b5c326fa",
   "metadata": {},
   "source": [
    "### 2. Limpieza de los campos geográficos \n",
    "\n",
    "A continuación, se realiza la limpieza de los campos de “Country” y “City” para homogenizar los nombres de los lugares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dba2951-609b-4a2d-937c-da386d6f5677",
   "metadata": {},
   "source": [
    "Primero, se realiza la limpieza del campo **country**. Se tiene en cuenta la función *clean_country* del paquete *dataprep* para la estandarización del campo mencionado pues la función limpia una columna que contiene nombres de países y/o códigos de país ISO 3166, y los normaliza en el formato deseado. Sin embargo, hay nombres de paises que no son resultos por la función pues tienen errores de escritura. De esta manera, se realiza una limpieza manual usando un diccionario con solo los textos faltantes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec054889-13c7-437d-9a70-aee3b5ca6109",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dict = {'UK': 'U.K.', 'Scotland ': 'U.K.', 'England': 'U.K.','ENGLAND': 'U.K.', 'England ': 'U.K.', 'Scotland': 'U.K.', 'Uk': 'U.K.', 'England/UK': 'U.K.',\n",
    "                'U.S>': 'USA', 'ISA': 'USA', 'United State': 'USA', 'America': 'USA', 'United State of America': 'USA', 'United Statws': 'USA', 'U.S': 'USA',\n",
    "                'Unites States': 'USA', 'U. S. ': 'USA', 'United Sates': 'USA', 'Uniited States': 'USA', 'United Sates of America': 'USA',  'Unted States': 'USA',\n",
    "                'United Stattes': 'USA', 'United Statea': 'USA', 'United Statea': 'USA', 'Unites States': 'USA', 'United Statees': 'USA', 'Uniyed states': 'USA', \n",
    "                'Uniyes States': 'USA', 'U.A.': 'USA', 'U. S.': 'USA', ' US of A': 'USA', 'United Kindom': 'U.K.', 'United Status': 'USA', 'Uniteed States': 'USA',\n",
    "                'United Stares': 'USA', 'United Stares': 'USA', 'Unites states ': 'USA', 'The US': 'USA', 'UnitedStates': 'USA', 'United statew': 'USA',\n",
    "                'United Statues': 'USA', 'United Statues': 'USA', 'Untied States': 'USA',  'Unitied States': 'USA', ' United Sttes': 'USA',\n",
    "                'united stated': 'USA', ' Uniter Statez': 'USA', 'U. S ': 'USA', 'United Stateds': 'USA', 'Unitef Stated': 'USA',\n",
    "                'United Stares ': 'USA', 'USaa': 'USA', 'america': 'USA', 'United Statss': 'USA', 'United  States': 'USA','United Stated\t': 'USA','Northern Ireland\t': \"Ireland\"}\n",
    "\n",
    "df['country'] = df['country'].map(country_dict).fillna(df['country'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89969f35-7b16-4b6f-9332-4953338bf8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                            | 0/8 [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country Cleaning Report:\n",
      "\t15489 values cleaned (55.44%)\n",
      "\t133 values unable to be parsed (0.48%), set to NaN\n",
      "Result contains 27803 (99.52%) values in the correct format and 133 null values (0.48%)\n"
     ]
    }
   ],
   "source": [
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "df = clean_country(df, 'country', output_format= \"name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198e3062-a181-4cc7-bb66-e7d11d69c204",
   "metadata": {},
   "source": [
    "Cabe mencionar que el diccionario solo cuenta con los nombres de los paises que no son posibles de traducir por la función. Lo anterior, nos apoya en el proceso de limpieza pues no es necesario realizar una limpieza manual a muchos registros sino solo aquellos que la función no leyo. Teniendo en cuenta que de los registros originales de la base de datos solo un 0.48% (133 registros) no fueron estandarizados, se decide eliminar aquellos registros que no pasaron satisfactoriamente por el proceso de limpieza.  \n",
    "\n",
    "Finalemente, se crea una nueva variable **Country_clean** con los países estandarizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5f87c7a-a023-4770-a7bc-92e1f1c0fc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.dropna(subset=['country_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cdf690-61c9-415b-bd00-8ff32690bab6",
   "metadata": {},
   "source": [
    "Ahora, se realiza la limpieza del campo **city**. Primero, se eliminar las filas que presenten ciudades en valores faltantes. Luego, se revisan y organizan las ciudades en una lista para aplicar la métrica de similitud de textos del paquete *fuzzywuzzy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "803d23a3-a8b7-43d7-83b2-22d9eca3988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.dropna(subset=['city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50f45ce8-544b-4105-9d8c-81076cc4c750",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities = df_clean[\"city\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26a9d2a2-c67e-4dfd-acad-501176d4daaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spaces(strings):\n",
    "    return [string.strip() for string in strings]\n",
    "city_no_spaces = remove_spaces(df_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cfb1748-2cf5-45d3-bde0-a361a103998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_values(lst):\n",
    "    return list(set(lst))\n",
    "unique_cities = get_unique_values(city_no_spaces)\n",
    "sorted_unique_cities = sorted(unique_cities)[16:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67773f05-b1d5-486c-aaf2-c1a5df1b3940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4168"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_unique_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4e8f0c7-2f8c-4183-8e03-5bbbb06487ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_sort</th>\n",
       "      <th>match_sort</th>\n",
       "      <th>score_sort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Coruña</td>\n",
       "      <td>A Coruña</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Coruña</td>\n",
       "      <td>Accra</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Coruña</td>\n",
       "      <td>Victorua</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Coruña</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Coruña</td>\n",
       "      <td>Anchoragr</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city_sort match_sort  score_sort\n",
       "0  A Coruña   A Coruña         100\n",
       "1  A Coruña      Accra          67\n",
       "2  A Coruña   Victorua          67\n",
       "3  A Coruña  Anchorage          62\n",
       "4  A Coruña  Anchoragr          62"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_sort = [(x,) + i\n",
    "             for x in sorted_unique_cities\n",
    "             for i in process.extract(x, sorted_unique_cities, scorer=fuzz.token_set_ratio)]\n",
    "#Create a dataframe from the tuples\n",
    "similarity_sort = pd.DataFrame(score_sort, columns=['city_sort','match_sort','score_sort'])\n",
    "similarity_sort.head()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aec0d752-6e23-49c3-ab89-6e706c49b2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_sort</th>\n",
       "      <th>match_sort</th>\n",
       "      <th>score_sort</th>\n",
       "      <th>sorted_city_sort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Coruña</td>\n",
       "      <td>A Coruña</td>\n",
       "      <td>100</td>\n",
       "      <td>A Coruña</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Coruña</td>\n",
       "      <td>Accra</td>\n",
       "      <td>67</td>\n",
       "      <td>A Coruña</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Coruña</td>\n",
       "      <td>Victorua</td>\n",
       "      <td>67</td>\n",
       "      <td>A Coruña</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Coruña</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>62</td>\n",
       "      <td>A Coruña</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Coruña</td>\n",
       "      <td>Anchoragr</td>\n",
       "      <td>62</td>\n",
       "      <td>A Coruña</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city_sort match_sort  score_sort sorted_city_sort\n",
       "0  A Coruña   A Coruña         100         A Coruña\n",
       "1  A Coruña      Accra          67         A Coruña\n",
       "2  A Coruña   Victorua          67         A Coruña\n",
       "3  A Coruña  Anchorage          62         A Coruña\n",
       "4  A Coruña  Anchoragr          62         A Coruña"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_sort['sorted_city_sort'] = np.minimum(similarity_sort['city_sort'], similarity_sort['match_sort'])\n",
    "similarity_sort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b6d8f08-b1cf-4c5d-9c4d-bc550631ccc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_sort</th>\n",
       "      <th>match_sort</th>\n",
       "      <th>score_sort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A city in the UK</td>\n",
       "      <td>City</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A city in the UK</td>\n",
       "      <td>UK</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A city in the UK</td>\n",
       "      <td>Uk</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A city small enough to not answer this question</td>\n",
       "      <td>A small city</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A city small enough to not answer this question</td>\n",
       "      <td>City</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20468</th>\n",
       "      <td>rather not say</td>\n",
       "      <td>rather not say (too identifiable)</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20469</th>\n",
       "      <td>rather not say</td>\n",
       "      <td>would rather not say</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20487</th>\n",
       "      <td>regional</td>\n",
       "      <td>regional city</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20501</th>\n",
       "      <td>remove</td>\n",
       "      <td>would remove my anonymity to state this</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20627</th>\n",
       "      <td>small college town</td>\n",
       "      <td>small town</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2330 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             city_sort  \\\n",
       "6                                     A city in the UK   \n",
       "7                                     A city in the UK   \n",
       "8                                     A city in the UK   \n",
       "11     A city small enough to not answer this question   \n",
       "12     A city small enough to not answer this question   \n",
       "...                                                ...   \n",
       "20468                                   rather not say   \n",
       "20469                                   rather not say   \n",
       "20487                                         regional   \n",
       "20501                                           remove   \n",
       "20627                               small college town   \n",
       "\n",
       "                                    match_sort  score_sort  \n",
       "6                                         City         100  \n",
       "7                                           UK         100  \n",
       "8                                           Uk         100  \n",
       "11                                A small city         100  \n",
       "12                                        City         100  \n",
       "...                                        ...         ...  \n",
       "20468        rather not say (too identifiable)         100  \n",
       "20469                     would rather not say         100  \n",
       "20487                            regional city         100  \n",
       "20501  would remove my anonymity to state this         100  \n",
       "20627                               small town         100  \n",
       "\n",
       "[2330 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_score_sort = similarity_sort[(similarity_sort['score_sort'] >= 98) &\n",
    "                (similarity_sort['city_sort'] !=  similarity_sort['match_sort']) &\n",
    "                (similarity_sort['sorted_city_sort'] != similarity_sort['match_sort'])]\n",
    "high_score_sort = high_score_sort.drop('sorted_city_sort',axis=1).copy()\n",
    "high_score_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a90a93d4-5128-43de-b73f-5774ded8fa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_clean.iterrows():\n",
    "  c = high_score_sort[high_score_sort['match_sort'] == row['city']]\n",
    "  if c.empty == False:\n",
    "    df_clean.loc[index, 'city_clean'] = c.iloc[0]['city_sort']\n",
    "  else:\n",
    "    df_clean.loc[index, 'city_clean'] = row['city']\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c4ce570-4c90-4583-ac15-6cb684d0e630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3707"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# se reduce la cantidad de valores unicos de la columna City\n",
    "len(df_clean['city_clean'].unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35b1807-3a97-4708-8a44-b7855ee71e37",
   "metadata": {},
   "source": [
    "Aplicando la métrica de similitud de textos, logramos disminuir la cantidad de países únicos en aproximadamente 500. Finalmente, se crea un nuevo campo llamado *city_clean* donde estan las ciudades estandarizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e742c22-4429-43d5-a28f-a9bb8b420c92",
   "metadata": {},
   "source": [
    "### 3. Crear campos nuevos: “salario_anual” y “compensaciones” \n",
    "\n",
    "Para crear los campos mencionados, se tuvo en cuenta la conversión de sueldos y compensaciones a Pesos Colombianos basados en la tasa de cambio del día 12/02/2023. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e4769e8-c8d4-4cfd-b2f3-d69d31169f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ZAR',\n",
       " 'GBP',\n",
       " 'Other',\n",
       " 'HKD',\n",
       " 'JPY',\n",
       " 'AUD/NZD',\n",
       " 'CHF',\n",
       " 'EUR',\n",
       " 'CAD',\n",
       " 'SEK',\n",
       " 'USD']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se revisan las divisas que aparecen\n",
    "def get_unique_values_of_column(df, column_name):\n",
    "    column = df[column_name].tolist()\n",
    "    return list(set(column))\n",
    "unique_currency = get_unique_values_of_column(df_clean,\"currency\")\n",
    "unique_currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39122ee3-da70-46c4-9355-e69faf32af69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tipo de cambio obtenido el 12/02/2023 por https://www.xe.com/currencyconverter/\n",
    "currency_dict = {'USD': 4803.71, 'AUD/NZD': 3020.89, 'GBP': 5782.32, 'CHF': 5187.04,'HKD': 611.47,'EUR': 5119.48,'SEK': 457.31, 'CAD': 3586.98, 'Other': 4803.71,  \n",
    "                 'ZAR': 267.51,  'JPY': 36.40}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53875ccc-7fa2-4609-a559-5fccbc09fb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir a pesos colombianos\n",
    "df_clean['salario_anual'] = df_clean.apply(lambda row: row['annual_salary']*currency_dict[row['currency']], axis=1)\n",
    "df_clean['compensaciones'] = df_clean.apply(lambda row: row['additional_monetary_compensation']*currency_dict[row['currency']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5c178d-e77d-4157-929f-e20f6c36f502",
   "metadata": {},
   "source": [
    "### 4. Crear un campo adicional del salario total en pesos colombianos \n",
    "\n",
    "A continuación, se crea el campo adicional sumando salario anual y compensaciones en pesos colombianos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5067bda9-b5d5-4ad6-aba4-b345e60314f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['ingreso_total'] = df_clean.apply(lambda row:  row['salario_anual'] + row['compensaciones'] if ~np.isnan(row['compensaciones']) else row['salario_anual'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03db0a2-6102-495a-9e20-c081a4a47cfb",
   "metadata": {},
   "source": [
    "### Guardar archivo con el modelamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa05c63f-c1a0-4c33-b1fa-eea7212586de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_excel(\"V&S_Encuestas_clean.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
